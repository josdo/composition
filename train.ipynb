{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\n",
      "Collecting numpy==1.16.0\n",
      "  Downloading numpy-1.16.0-cp37-cp37m-manylinux1_x86_64.whl (17.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3 MB 17 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (4.4.0.42)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (4.48.2)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.7/site-packages (2.1.1)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.1-py2.py3-none-any.whl (308 kB)\n",
      "\u001b[K     |████████████████████████████████| 308 kB 18.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (5.3.1)\n",
      "Collecting webcolors\n",
      "  Downloading webcolors-1.11.1-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (3.3.1)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (49.6.0.post20200814)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (0.29.21)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.15.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.8.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (3.12.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (2.24.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.20.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (1.31.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.35.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (3.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.6)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.1.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=278730 sha256=0af9abe73f09aec281f1bec41644000cb16ebc339fa32d5dd4c9023a34a2deda\n",
      "  Stored in directory: /home/sleepearly/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pycocotools, numpy, tensorboardX, webcolors\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.1\n",
      "    Uninstalling numpy-1.19.1:\n",
      "      Successfully uninstalled numpy-1.19.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tfx-bsl 0.22.0 requires pyarrow<0.17,>=0.16.0, but you'll have pyarrow 0.17.1 which is incompatible.\n",
      "tensorflow 2.2.0 requires gast==0.3.3, but you'll have gast 0.2.2 which is incompatible.\n",
      "tensorflow 2.2.0 requires scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.2 which is incompatible.\n",
      "tensorflow 2.2.0 requires tensorboard<2.3.0,>=2.2.0, but you'll have tensorboard 2.1.1 which is incompatible.\n",
      "tensorflow 2.2.0 requires tensorflow-estimator<2.3.0,>=2.2.0, but you'll have tensorflow-estimator 2.1.0 which is incompatible.\n",
      "tensorflow-serving-api 2.1.0 requires tensorflow~=2.1.0, but you'll have tensorflow 2.2.0 which is incompatible.\n",
      "tensorflow-model-analysis 0.22.1 requires pyarrow<0.17,>=0.16, but you'll have pyarrow 0.17.1 which is incompatible.\n",
      "tensorflow-model-analysis 0.22.1 requires scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.2 which is incompatible.\n",
      "tensorflow-gpu 2.1.0 requires scipy==1.4.1; python_version >= \"3\", but you'll have scipy 1.5.2 which is incompatible.\n",
      "tensorflow-data-validation 0.22.0 requires joblib<0.15,>=0.12, but you'll have joblib 0.16.0 which is incompatible.\n",
      "tensorflow-data-validation 0.22.0 requires pandas<1,>=0.24, but you'll have pandas 1.1.1 which is incompatible.\n",
      "tensorflow-data-validation 0.22.0 requires pyarrow<0.17,>=0.16, but you'll have pyarrow 0.17.1 which is incompatible.\n",
      "pandas-profiling 2.8.0 requires visions[type_image_path]==0.4.4, but you'll have visions 0.5.0 which is incompatible.\n",
      "ml-metadata 0.22.0 requires tensorflow!=2.0.*,!=2.2.0,<3,>=1.15, but you'll have tensorflow 2.2.0 which is incompatible.\n",
      "apache-beam 2.22.0 requires httplib2<0.18.0,>=0.8, but you'll have httplib2 0.18.1 which is incompatible.\n",
      "apache-beam 2.22.0 requires mock<3.0.0,>=1.0.1, but you'll have mock 4.0.2 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.18.5 pycocotools-2.0.2 tensorboardX-2.1 webcolors-1.11.1\n",
      "Collecting torch==1.4.0\n",
      "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4 MB 3.0 kB/s  eta 0:00:01    |███▏                            | 74.6 MB 32.8 MB/s eta 0:00:21\n",
      "\u001b[?25hInstalling collected packages: torch\n",
      "Successfully installed torch-1.4.0\n",
      "Collecting torchvision==0.5.0\n",
      "  Downloading torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch==1.4.0 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.5.0) (1.4.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.5.0) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.5.0) (7.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchvision==0.5.0) (1.15.0)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.5.0\n"
     ]
    }
   ],
   "source": [
    "# Requirements\n",
    "!pip install pycocotools numpy==1.16.0 opencv-python tqdm tensorboard tensorboardX pyyaml webcolors matplotlib\n",
    "!pip install torch==1.4.0\n",
    "!pip install torchvision==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_name: peopleart_coco  # also the folder name of the dataset that under data_path folder\r\n",
      "train_set: train\r\n",
      "val_set: val\r\n",
      "num_gpus: 1\r\n",
      "\r\n",
      "# mean and std in RGB order, actually this part should remain unchanged as long as your dataset is similar to coco.\r\n",
      "mean: [0.485, 0.456, 0.406]\r\n",
      "std: [0.229, 0.224, 0.225]\r\n",
      "\r\n",
      "# this is coco anchors, change it if necessary\r\n",
      "anchors_scales: '[2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]'\r\n",
      "anchors_ratios: '[(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)]'\r\n",
      "\r\n",
      "# must match your dataset's category_id.\r\n",
      "# category_id is one_indexed,\r\n",
      "# for example, index of 'car' here is 2, while category_id of is 3\r\n",
      "obj_list: ['person']"
     ]
    }
   ],
   "source": [
    "# Download pretrained weights\n",
    "# ! mkdir weights\n",
    "# ! wget https://github.com/zylo117/Yet-Another-EfficientDet-Pytorch/releases/download/1.0/efficientdet-d0.pth -O weights/efficientdet-d0.pth\n",
    "\n",
    "# Prepare project file\n",
    "! cat projects/peopleart_coco.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "[Warning] Ignoring Error(s) in loading state_dict for EfficientDetBackbone:\n",
      "\tsize mismatch for classifier.header.pointwise_conv.conv.weight: copying a param with shape torch.Size([810, 64, 1, 1]) from checkpoint, the shape in current model is torch.Size([9, 64, 1, 1]).\n",
      "\tsize mismatch for classifier.header.pointwise_conv.conv.bias: copying a param with shape torch.Size([810]) from checkpoint, the shape in current model is torch.Size([9]).\n",
      "[Warning] Don't panic if you see this, this might be because you load a pretrained weights with different number of classes. The rest of the weights should be loaded already.\n",
      "[Info] loaded weights: efficientdet-d0.pth, resuming checkpoint from step: 0\n",
      "[Info] freezed backbone\n",
      "Step: 3. Epoch: 0/200. Iteration: 4/4. Cls loss: 501.85269. Reg loss: 2.25582. T\n",
      "Val. Epoch: 0/200. Classification loss: 486.24485. Regression loss: 2.17914. Total loss: 488.42399\n",
      "Step: 7. Epoch: 1/200. Iteration: 4/4. Cls loss: 329.38876. Reg loss: 2.11042. T\n",
      "Step: 11. Epoch: 2/200. Iteration: 4/4. Cls loss: 347.35175. Reg loss: 2.15889. \n",
      "Step: 15. Epoch: 3/200. Iteration: 4/4. Cls loss: 145.26328. Reg loss: 2.15101. \n",
      "Step: 19. Epoch: 4/200. Iteration: 4/4. Cls loss: 95.81911. Reg loss: 1.89679. T\n",
      "Val. Epoch: 4/200. Classification loss: 64.33201. Regression loss: 2.03575. Total loss: 66.36776\n",
      "Step: 23. Epoch: 5/200. Iteration: 4/4. Cls loss: 73.48231. Reg loss: 1.85537. T\n",
      "Step: 27. Epoch: 6/200. Iteration: 4/4. Cls loss: 36.59680. Reg loss: 2.22611. T\n",
      "Step: 31. Epoch: 7/200. Iteration: 4/4. Cls loss: 24.47129. Reg loss: 2.00897. T\n",
      "Step: 35. Epoch: 8/200. Iteration: 4/4. Cls loss: 15.45213. Reg loss: 1.89022. T\n",
      "Val. Epoch: 8/200. Classification loss: 8.45144. Regression loss: 2.04383. Total loss: 10.49527\n",
      "Step: 39. Epoch: 9/200. Iteration: 4/4. Cls loss: 7.55106. Reg loss: 2.13353. To\n",
      "Step: 43. Epoch: 10/200. Iteration: 4/4. Cls loss: 5.91873. Reg loss: 1.92793. T\n",
      "Step: 47. Epoch: 11/200. Iteration: 4/4. Cls loss: 5.77635. Reg loss: 1.95404. T\n",
      "Step: 51. Epoch: 12/200. Iteration: 4/4. Cls loss: 3.59927. Reg loss: 2.02505. T\n",
      "Val. Epoch: 12/200. Classification loss: 4.16842. Regression loss: 1.98804. Total loss: 6.15646\n",
      "Step: 55. Epoch: 13/200. Iteration: 4/4. Cls loss: 3.08800. Reg loss: 2.00333. T\n",
      "Step: 59. Epoch: 14/200. Iteration: 4/4. Cls loss: 2.71890. Reg loss: 2.04467. T\n",
      "Step: 63. Epoch: 15/200. Iteration: 4/4. Cls loss: 2.49400. Reg loss: 1.88055. T\n",
      "Step: 67. Epoch: 16/200. Iteration: 4/4. Cls loss: 2.31667. Reg loss: 1.82463. T\n",
      "Val. Epoch: 16/200. Classification loss: 2.64199. Regression loss: 1.99983. Total loss: 4.64182\n",
      "Step: 71. Epoch: 17/200. Iteration: 4/4. Cls loss: 2.50125. Reg loss: 1.96025. T\n",
      "Step: 75. Epoch: 18/200. Iteration: 4/4. Cls loss: 2.06262. Reg loss: 2.02343. T\n",
      "Step: 79. Epoch: 19/200. Iteration: 4/4. Cls loss: 1.92118. Reg loss: 1.90182. T\n",
      "Step: 83. Epoch: 20/200. Iteration: 4/4. Cls loss: 1.91286. Reg loss: 2.02125. T\n",
      "Val. Epoch: 20/200. Classification loss: 2.10811. Regression loss: 1.99419. Total loss: 4.10230\n",
      "Step: 87. Epoch: 21/200. Iteration: 4/4. Cls loss: 2.17915. Reg loss: 1.93652. T\n",
      "Step: 91. Epoch: 22/200. Iteration: 4/4. Cls loss: 1.64745. Reg loss: 1.86725. T\n",
      "Step: 95. Epoch: 23/200. Iteration: 4/4. Cls loss: 1.88638. Reg loss: 1.82407. T\n",
      "Step: 99. Epoch: 24/200. Iteration: 4/4. Cls loss: 1.69684. Reg loss: 1.93707. Tcheckpoint...\n",
      "Step: 99. Epoch: 24/200. Iteration: 4/4. Cls loss: 1.69684. Reg loss: 1.93707. T\n",
      "Val. Epoch: 24/200. Classification loss: 1.83462. Regression loss: 2.01439. Total loss: 3.84900\n",
      "Step: 103. Epoch: 25/200. Iteration: 4/4. Cls loss: 1.46526. Reg loss: 1.89214. \n",
      "Step: 107. Epoch: 26/200. Iteration: 4/4. Cls loss: 1.58707. Reg loss: 1.85097. \n",
      "Step: 111. Epoch: 27/200. Iteration: 4/4. Cls loss: 1.64092. Reg loss: 1.83080. \n",
      "Step: 115. Epoch: 28/200. Iteration: 4/4. Cls loss: 1.40234. Reg loss: 1.83984. \n",
      "Val. Epoch: 28/200. Classification loss: 1.64636. Regression loss: 2.00279. Total loss: 3.64915\n",
      "Step: 119. Epoch: 29/200. Iteration: 4/4. Cls loss: 1.32587. Reg loss: 1.98423. \n",
      "Step: 123. Epoch: 30/200. Iteration: 4/4. Cls loss: 1.49960. Reg loss: 1.94813. \n",
      "Step: 127. Epoch: 31/200. Iteration: 4/4. Cls loss: 1.53815. Reg loss: 1.74244. \n",
      "Step: 131. Epoch: 32/200. Iteration: 4/4. Cls loss: 1.28345. Reg loss: 1.84745. \n",
      "Val. Epoch: 32/200. Classification loss: 1.49150. Regression loss: 2.02656. Total loss: 3.51806\n",
      "Step: 135. Epoch: 33/200. Iteration: 4/4. Cls loss: 1.11062. Reg loss: 1.82723. \n",
      "Step: 139. Epoch: 34/200. Iteration: 4/4. Cls loss: 1.24122. Reg loss: 1.81349. \n",
      "Step: 143. Epoch: 35/200. Iteration: 4/4. Cls loss: 1.06915. Reg loss: 1.77067. \n",
      "Step: 147. Epoch: 36/200. Iteration: 4/4. Cls loss: 1.18138. Reg loss: 1.83521. \n",
      "Val. Epoch: 36/200. Classification loss: 1.36609. Regression loss: 2.02782. Total loss: 3.39390\n",
      "Step: 151. Epoch: 37/200. Iteration: 4/4. Cls loss: 1.20609. Reg loss: 1.76304. \n",
      "Step: 155. Epoch: 38/200. Iteration: 4/4. Cls loss: 1.20181. Reg loss: 1.71109. \n",
      "Step: 159. Epoch: 39/200. Iteration: 4/4. Cls loss: 1.01146. Reg loss: 1.73289. \n",
      "Step: 163. Epoch: 40/200. Iteration: 4/4. Cls loss: 1.02415. Reg loss: 1.78648. \n",
      "Val. Epoch: 40/200. Classification loss: 1.25186. Regression loss: 2.05363. Total loss: 3.30548\n",
      "Step: 167. Epoch: 41/200. Iteration: 4/4. Cls loss: 1.07777. Reg loss: 1.87873. \n",
      "Step: 171. Epoch: 42/200. Iteration: 4/4. Cls loss: 1.04013. Reg loss: 1.91878. \n",
      "Step: 175. Epoch: 43/200. Iteration: 4/4. Cls loss: 1.01176. Reg loss: 1.87207. \n",
      "Step: 179. Epoch: 44/200. Iteration: 4/4. Cls loss: 0.98002. Reg loss: 1.73156. \n",
      "Val. Epoch: 44/200. Classification loss: 1.15687. Regression loss: 2.04798. Total loss: 3.20484\n",
      "Step: 183. Epoch: 45/200. Iteration: 4/4. Cls loss: 1.07116. Reg loss: 1.72184. \n",
      "Step: 187. Epoch: 46/200. Iteration: 4/4. Cls loss: 1.07356. Reg loss: 1.71789. \n",
      "Step: 191. Epoch: 47/200. Iteration: 4/4. Cls loss: 0.96851. Reg loss: 1.78542. \n",
      "Step: 195. Epoch: 48/200. Iteration: 4/4. Cls loss: 0.85680. Reg loss: 1.82787. \n",
      "Val. Epoch: 48/200. Classification loss: 1.07199. Regression loss: 2.07938. Total loss: 3.15137\n",
      "Step: 199. Epoch: 49/200. Iteration: 4/4. Cls loss: 0.89139. Reg loss: 1.58949. checkpoint...\n",
      "Step: 199. Epoch: 49/200. Iteration: 4/4. Cls loss: 0.89139. Reg loss: 1.58949. \n",
      "Step: 203. Epoch: 50/200. Iteration: 4/4. Cls loss: 0.97970. Reg loss: 1.77508. \n",
      "Step: 207. Epoch: 51/200. Iteration: 4/4. Cls loss: 0.93959. Reg loss: 1.75416. \n",
      "Step: 211. Epoch: 52/200. Iteration: 4/4. Cls loss: 0.84088. Reg loss: 1.74104. \n",
      "Val. Epoch: 52/200. Classification loss: 0.99667. Regression loss: 2.06791. Total loss: 3.06458\n",
      "Step: 215. Epoch: 53/200. Iteration: 4/4. Cls loss: 0.88238. Reg loss: 1.91578. \n",
      "Step: 219. Epoch: 54/200. Iteration: 4/4. Cls loss: 0.91897. Reg loss: 1.68277. \n",
      "Step: 223. Epoch: 55/200. Iteration: 4/4. Cls loss: 0.89600. Reg loss: 1.72806. \n",
      "Step: 227. Epoch: 56/200. Iteration: 4/4. Cls loss: 0.80929. Reg loss: 1.80836. \n",
      "Val. Epoch: 56/200. Classification loss: 0.93017. Regression loss: 2.06742. Total loss: 2.99758\n",
      "Step: 231. Epoch: 57/200. Iteration: 4/4. Cls loss: 0.83210. Reg loss: 1.66198. \n",
      "Step: 235. Epoch: 58/200. Iteration: 4/4. Cls loss: 0.79696. Reg loss: 1.84135. \n",
      "Step: 239. Epoch: 59/200. Iteration: 4/4. Cls loss: 0.77966. Reg loss: 1.69596. \n",
      "Step: 243. Epoch: 60/200. Iteration: 4/4. Cls loss: 0.85736. Reg loss: 1.73237. \n",
      "Val. Epoch: 60/200. Classification loss: 0.87235. Regression loss: 2.08722. Total loss: 2.95957\n",
      "Step: 247. Epoch: 61/200. Iteration: 4/4. Cls loss: 0.81756. Reg loss: 1.60953. \n",
      "Step: 251. Epoch: 62/200. Iteration: 4/4. Cls loss: 0.89613. Reg loss: 1.69969. \n",
      "Step: 255. Epoch: 63/200. Iteration: 4/4. Cls loss: 0.73649. Reg loss: 1.67018. \n",
      "Step: 259. Epoch: 64/200. Iteration: 4/4. Cls loss: 0.70564. Reg loss: 1.59091. \n",
      "Val. Epoch: 64/200. Classification loss: 0.82314. Regression loss: 2.09683. Total loss: 2.91998\n",
      "Step: 263. Epoch: 65/200. Iteration: 4/4. Cls loss: 0.71314. Reg loss: 1.77079. \n",
      "Step: 267. Epoch: 66/200. Iteration: 4/4. Cls loss: 0.73597. Reg loss: 1.76757. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 271. Epoch: 67/200. Iteration: 4/4. Cls loss: 0.68329. Reg loss: 1.69872. \n",
      "Step: 275. Epoch: 68/200. Iteration: 4/4. Cls loss: 0.70611. Reg loss: 1.68388. \n",
      "Val. Epoch: 68/200. Classification loss: 0.77873. Regression loss: 2.10450. Total loss: 2.88323\n",
      "Step: 279. Epoch: 69/200. Iteration: 4/4. Cls loss: 0.68604. Reg loss: 1.89082. \n",
      "Step: 283. Epoch: 70/200. Iteration: 4/4. Cls loss: 0.64956. Reg loss: 1.71787. \n",
      "Step: 287. Epoch: 71/200. Iteration: 4/4. Cls loss: 0.71865. Reg loss: 1.46946. \n",
      "Step: 291. Epoch: 72/200. Iteration: 4/4. Cls loss: 0.73167. Reg loss: 1.65770. \n",
      "Val. Epoch: 72/200. Classification loss: 0.73871. Regression loss: 2.10130. Total loss: 2.84001\n",
      "Step: 295. Epoch: 73/200. Iteration: 4/4. Cls loss: 0.64017. Reg loss: 1.63227. \n",
      "Step: 299. Epoch: 74/200. Iteration: 4/4. Cls loss: 0.61828. Reg loss: 1.57139. checkpoint...\n",
      "Step: 299. Epoch: 74/200. Iteration: 4/4. Cls loss: 0.61828. Reg loss: 1.57139. \n",
      "Step: 303. Epoch: 75/200. Iteration: 4/4. Cls loss: 0.62310. Reg loss: 1.62546. \n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Step: 307. Epoch: 76/200. Iteration: 4/4. Cls loss: 0.65828. Reg loss: 1.76987. \n",
      "Val. Epoch: 76/200. Classification loss: 0.70932. Regression loss: 2.09765. Total loss: 2.80697\n",
      "Step: 311. Epoch: 77/200. Iteration: 4/4. Cls loss: 0.67364. Reg loss: 1.56509. \n",
      "Step: 315. Epoch: 78/200. Iteration: 4/4. Cls loss: 0.63923. Reg loss: 1.60670. \n",
      "Step: 319. Epoch: 79/200. Iteration: 4/4. Cls loss: 0.67065. Reg loss: 1.61226. \n",
      "Step: 323. Epoch: 80/200. Iteration: 4/4. Cls loss: 0.66322. Reg loss: 1.70283. \n",
      "Val. Epoch: 80/200. Classification loss: 0.69747. Regression loss: 2.09487. Total loss: 2.79234\n",
      "Step: 327. Epoch: 81/200. Iteration: 4/4. Cls loss: 0.65188. Reg loss: 1.68420. \n",
      "Step: 331. Epoch: 82/200. Iteration: 4/4. Cls loss: 0.60067. Reg loss: 1.77405. \n",
      "Step: 335. Epoch: 83/200. Iteration: 4/4. Cls loss: 0.64280. Reg loss: 1.58349. \n",
      "Step: 339. Epoch: 84/200. Iteration: 4/4. Cls loss: 0.68268. Reg loss: 1.75226. \n",
      "Val. Epoch: 84/200. Classification loss: 0.68690. Regression loss: 2.09441. Total loss: 2.78131\n",
      "Step: 343. Epoch: 85/200. Iteration: 4/4. Cls loss: 0.67899. Reg loss: 1.77296. \n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Step: 347. Epoch: 86/200. Iteration: 4/4. Cls loss: 0.63791. Reg loss: 1.65283. \n",
      "Step: 351. Epoch: 87/200. Iteration: 4/4. Cls loss: 0.64541. Reg loss: 1.65030. \n",
      "Step: 355. Epoch: 88/200. Iteration: 4/4. Cls loss: 0.71237. Reg loss: 1.58370. \n",
      "Val. Epoch: 88/200. Classification loss: 0.67951. Regression loss: 2.09500. Total loss: 2.77452\n",
      "Step: 359. Epoch: 89/200. Iteration: 4/4. Cls loss: 0.60925. Reg loss: 1.61375. \n",
      "Step: 363. Epoch: 90/200. Iteration: 4/4. Cls loss: 0.65673. Reg loss: 1.47701. \n",
      "Step: 367. Epoch: 91/200. Iteration: 4/4. Cls loss: 0.64723. Reg loss: 1.53278. \n",
      "Step: 371. Epoch: 92/200. Iteration: 4/4. Cls loss: 0.64254. Reg loss: 1.64303. \n",
      "Val. Epoch: 92/200. Classification loss: 0.67362. Regression loss: 2.09378. Total loss: 2.76740\n",
      "Step: 375. Epoch: 93/200. Iteration: 4/4. Cls loss: 0.67232. Reg loss: 1.69166. \n",
      "Step: 379. Epoch: 94/200. Iteration: 4/4. Cls loss: 0.66272. Reg loss: 1.65199. \n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Step: 383. Epoch: 95/200. Iteration: 4/4. Cls loss: 0.69672. Reg loss: 1.67236. \n",
      "Step: 387. Epoch: 96/200. Iteration: 4/4. Cls loss: 0.64172. Reg loss: 1.66389. \n",
      "Val. Epoch: 96/200. Classification loss: 0.66890. Regression loss: 2.09390. Total loss: 2.76280\n",
      "Step: 391. Epoch: 97/200. Iteration: 4/4. Cls loss: 0.60829. Reg loss: 1.65653. \n",
      "Step: 395. Epoch: 98/200. Iteration: 4/4. Cls loss: 0.78287. Reg loss: 1.70140. \n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Step: 399. Epoch: 99/200. Iteration: 4/4. Cls loss: 0.60551. Reg loss: 1.60448. checkpoint...\n",
      "Step: 399. Epoch: 99/200. Iteration: 4/4. Cls loss: 0.60551. Reg loss: 1.60448. \n",
      "Step: 403. Epoch: 100/200. Iteration: 4/4. Cls loss: 0.62576. Reg loss: 1.48886.\n",
      "Val. Epoch: 100/200. Classification loss: 0.66540. Regression loss: 2.09429. Total loss: 2.75970\n",
      "Step: 407. Epoch: 101/200. Iteration: 4/4. Cls loss: 0.63382. Reg loss: 1.63998.\n",
      "Step: 411. Epoch: 102/200. Iteration: 4/4. Cls loss: 0.62910. Reg loss: 1.68785.\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Step: 415. Epoch: 103/200. Iteration: 4/4. Cls loss: 0.59860. Reg loss: 1.58711.\n",
      "Step: 419. Epoch: 104/200. Iteration: 4/4. Cls loss: 0.61149. Reg loss: 1.55857.\n",
      "Val. Epoch: 104/200. Classification loss: 0.66230. Regression loss: 2.09486. Total loss: 2.75715\n",
      "Step: 423. Epoch: 105/200. Iteration: 4/4. Cls loss: 0.59691. Reg loss: 1.63363.\n",
      "Step: 427. Epoch: 106/200. Iteration: 4/4. Cls loss: 0.58951. Reg loss: 1.54175.\n",
      "Step: 431. Epoch: 107/200. Iteration: 4/4. Cls loss: 0.56526. Reg loss: 1.59942.\n",
      "Step: 435. Epoch: 108/200. Iteration: 4/4. Cls loss: 0.63400. Reg loss: 1.58582.\n",
      "Val. Epoch: 108/200. Classification loss: 0.65932. Regression loss: 2.09556. Total loss: 2.75488\n",
      "Step: 439. Epoch: 109/200. Iteration: 4/4. Cls loss: 0.61710. Reg loss: 1.67087.\n",
      "Step: 443. Epoch: 110/200. Iteration: 4/4. Cls loss: 0.65685. Reg loss: 1.46216.\n",
      "Step: 447. Epoch: 111/200. Iteration: 4/4. Cls loss: 0.65246. Reg loss: 1.46290.\n",
      "Step: 451. Epoch: 112/200. Iteration: 4/4. Cls loss: 0.68818. Reg loss: 1.52377.\n",
      "Val. Epoch: 112/200. Classification loss: 0.65750. Regression loss: 2.09649. Total loss: 2.75399\n",
      "Step: 455. Epoch: 113/200. Iteration: 4/4. Cls loss: 0.68461. Reg loss: 1.50618.\n",
      "Step: 459. Epoch: 114/200. Iteration: 4/4. Cls loss: 0.62314. Reg loss: 1.51515.\n",
      "Step: 463. Epoch: 115/200. Iteration: 4/4. Cls loss: 0.63992. Reg loss: 1.64082.\n",
      "Step: 467. Epoch: 116/200. Iteration: 4/4. Cls loss: 0.57451. Reg loss: 1.53450.\n",
      "Val. Epoch: 116/200. Classification loss: 0.65585. Regression loss: 2.09763. Total loss: 2.75348\n",
      "Step: 471. Epoch: 117/200. Iteration: 4/4. Cls loss: 0.75842. Reg loss: 1.57545.\n",
      "Step: 475. Epoch: 118/200. Iteration: 4/4. Cls loss: 0.67325. Reg loss: 1.52956.\n",
      "Step: 479. Epoch: 119/200. Iteration: 4/4. Cls loss: 0.61780. Reg loss: 1.55431.\n",
      "Step: 483. Epoch: 120/200. Iteration: 4/4. Cls loss: 0.67242. Reg loss: 1.54590.\n",
      "Val. Epoch: 120/200. Classification loss: 0.65409. Regression loss: 2.09779. Total loss: 2.75189\n",
      "Step: 487. Epoch: 121/200. Iteration: 4/4. Cls loss: 0.66781. Reg loss: 1.59764.\n",
      "Step: 491. Epoch: 122/200. Iteration: 4/4. Cls loss: 0.66545. Reg loss: 1.49223.\n",
      "Step: 495. Epoch: 123/200. Iteration: 4/4. Cls loss: 0.65600. Reg loss: 1.67602.\n",
      "Step: 499. Epoch: 124/200. Iteration: 4/4. Cls loss: 0.65666. Reg loss: 1.62633.checkpoint...\n",
      "Step: 499. Epoch: 124/200. Iteration: 4/4. Cls loss: 0.65666. Reg loss: 1.62633.\n",
      "Val. Epoch: 124/200. Classification loss: 0.65325. Regression loss: 2.09851. Total loss: 2.75177\n",
      "Step: 503. Epoch: 125/200. Iteration: 4/4. Cls loss: 0.69124. Reg loss: 1.71350.\n",
      "Step: 507. Epoch: 126/200. Iteration: 4/4. Cls loss: 0.59659. Reg loss: 1.47119.\n",
      "Step: 511. Epoch: 127/200. Iteration: 4/4. Cls loss: 0.63776. Reg loss: 1.61467.\n",
      "Step: 515. Epoch: 128/200. Iteration: 4/4. Cls loss: 0.64909. Reg loss: 1.65318.\n",
      "Val. Epoch: 128/200. Classification loss: 0.65196. Regression loss: 2.09874. Total loss: 2.75069\n",
      "Step: 519. Epoch: 129/200. Iteration: 4/4. Cls loss: 0.62096. Reg loss: 1.67832.\n",
      "Step: 523. Epoch: 130/200. Iteration: 4/4. Cls loss: 0.64721. Reg loss: 1.58358.\n",
      "Step: 527. Epoch: 131/200. Iteration: 4/4. Cls loss: 0.60917. Reg loss: 1.62222.\n",
      "Step: 531. Epoch: 132/200. Iteration: 4/4. Cls loss: 0.62490. Reg loss: 1.50281.\n",
      "Val. Epoch: 132/200. Classification loss: 0.65142. Regression loss: 2.09977. Total loss: 2.75119\n",
      "Step: 535. Epoch: 133/200. Iteration: 4/4. Cls loss: 0.73899. Reg loss: 1.66140.\n",
      "Step: 539. Epoch: 134/200. Iteration: 4/4. Cls loss: 0.60723. Reg loss: 1.63747.\n",
      "Step: 543. Epoch: 135/200. Iteration: 4/4. Cls loss: 0.63048. Reg loss: 1.66626.\n",
      "Step: 547. Epoch: 136/200. Iteration: 4/4. Cls loss: 0.65352. Reg loss: 1.85245.\n",
      "Val. Epoch: 136/200. Classification loss: 0.65063. Regression loss: 2.10042. Total loss: 2.75105\n",
      "Step: 551. Epoch: 137/200. Iteration: 4/4. Cls loss: 0.68854. Reg loss: 1.62175.\n",
      "Step: 555. Epoch: 138/200. Iteration: 4/4. Cls loss: 0.62889. Reg loss: 1.68247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 559. Epoch: 139/200. Iteration: 4/4. Cls loss: 0.63938. Reg loss: 1.60551.\n",
      "Step: 563. Epoch: 140/200. Iteration: 4/4. Cls loss: 0.67251. Reg loss: 1.69817.\n",
      "Val. Epoch: 140/200. Classification loss: 0.65023. Regression loss: 2.10118. Total loss: 2.75141\n",
      "Step: 567. Epoch: 141/200. Iteration: 4/4. Cls loss: 0.63426. Reg loss: 1.52433.\n",
      "Step: 571. Epoch: 142/200. Iteration: 4/4. Cls loss: 0.62121. Reg loss: 1.56198.\n",
      "Step: 575. Epoch: 143/200. Iteration: 4/4. Cls loss: 0.69798. Reg loss: 1.55721.\n",
      "Step: 579. Epoch: 144/200. Iteration: 4/4. Cls loss: 0.68760. Reg loss: 1.45812.\n",
      "Val. Epoch: 144/200. Classification loss: 0.64952. Regression loss: 2.10112. Total loss: 2.75064\n",
      "Step: 583. Epoch: 145/200. Iteration: 4/4. Cls loss: 0.60261. Reg loss: 1.57885.\n",
      "Step: 587. Epoch: 146/200. Iteration: 4/4. Cls loss: 0.65232. Reg loss: 1.55348.\n",
      "Step: 591. Epoch: 147/200. Iteration: 4/4. Cls loss: 0.60311. Reg loss: 1.65270.\n",
      "Step: 595. Epoch: 148/200. Iteration: 4/4. Cls loss: 0.64305. Reg loss: 1.66106.\n",
      "Val. Epoch: 148/200. Classification loss: 0.64931. Regression loss: 2.10193. Total loss: 2.75124\n",
      "Step: 599. Epoch: 149/200. Iteration: 4/4. Cls loss: 0.62670. Reg loss: 1.57477.checkpoint...\n",
      "Step: 599. Epoch: 149/200. Iteration: 4/4. Cls loss: 0.62670. Reg loss: 1.57477.\n",
      "Step: 603. Epoch: 150/200. Iteration: 4/4. Cls loss: 0.67504. Reg loss: 1.68195.\n",
      "Step: 607. Epoch: 151/200. Iteration: 4/4. Cls loss: 0.63491. Reg loss: 1.78122.\n",
      "Step: 611. Epoch: 152/200. Iteration: 4/4. Cls loss: 0.69188. Reg loss: 1.61956.\n",
      "Val. Epoch: 152/200. Classification loss: 0.64903. Regression loss: 2.10213. Total loss: 2.75117\n",
      "Step: 615. Epoch: 153/200. Iteration: 4/4. Cls loss: 0.65969. Reg loss: 1.54243.\n",
      "Step: 619. Epoch: 154/200. Iteration: 4/4. Cls loss: 0.77297. Reg loss: 1.51282.\n",
      "Step: 623. Epoch: 155/200. Iteration: 4/4. Cls loss: 0.62402. Reg loss: 1.63504.\n",
      "Step: 627. Epoch: 156/200. Iteration: 4/4. Cls loss: 0.73375. Reg loss: 1.57585.\n",
      "Val. Epoch: 156/200. Classification loss: 0.64856. Regression loss: 2.10256. Total loss: 2.75112\n",
      "Step: 631. Epoch: 157/200. Iteration: 4/4. Cls loss: 0.66586. Reg loss: 1.68511.\n",
      "Step: 635. Epoch: 158/200. Iteration: 4/4. Cls loss: 0.60712. Reg loss: 1.65709.\n",
      "Step: 639. Epoch: 159/200. Iteration: 4/4. Cls loss: 0.64057. Reg loss: 1.53047.\n",
      "Step: 643. Epoch: 160/200. Iteration: 4/4. Cls loss: 0.59720. Reg loss: 1.51558.\n",
      "Val. Epoch: 160/200. Classification loss: 0.64802. Regression loss: 2.10296. Total loss: 2.75098\n",
      "Step: 647. Epoch: 161/200. Iteration: 4/4. Cls loss: 0.69968. Reg loss: 1.49692.\n",
      "Step: 651. Epoch: 162/200. Iteration: 4/4. Cls loss: 0.64711. Reg loss: 1.59772.\n",
      "Step: 655. Epoch: 163/200. Iteration: 4/4. Cls loss: 0.66657. Reg loss: 1.59875.\n",
      "Step: 659. Epoch: 164/200. Iteration: 4/4. Cls loss: 0.64213. Reg loss: 1.62406.\n",
      "Val. Epoch: 164/200. Classification loss: 0.64787. Regression loss: 2.10323. Total loss: 2.75110\n",
      "Step: 663. Epoch: 165/200. Iteration: 4/4. Cls loss: 0.61803. Reg loss: 1.65501.\n",
      "Step: 667. Epoch: 166/200. Iteration: 4/4. Cls loss: 0.61233. Reg loss: 1.68180.\n",
      "Step: 671. Epoch: 167/200. Iteration: 4/4. Cls loss: 0.67109. Reg loss: 1.72620.\n",
      "Step: 675. Epoch: 168/200. Iteration: 4/4. Cls loss: 0.64229. Reg loss: 1.50664.\n",
      "Val. Epoch: 168/200. Classification loss: 0.64805. Regression loss: 2.10363. Total loss: 2.75168\n",
      "Step: 679. Epoch: 169/200. Iteration: 4/4. Cls loss: 0.62641. Reg loss: 1.68270.\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "# Only head first\n",
    "! python train.py -c 0 -p peopleart_coco --head_only True \\\n",
    "    --lr 1e-3 --batch_size 128 --load_weights weights/efficientdet-d0.pth  \\\n",
    "    --num_epochs 200 --save_interval 100 --val_interval 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
